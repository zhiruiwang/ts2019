{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3 TS practical session: (1h30)\n",
    "\n",
    "# Using Pytorch : TimeSeries and Neural Nets `torch.nn` :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T20:27:54.605046Z",
     "start_time": "2019-12-13T20:27:52.622479Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll keep it simple and only consider 1-dimensional convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `torch.nn` interesting parts for series\n",
    "\n",
    "Before doing any specific task, lets just review some of the interesting bits available for timeseries in pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (A) Dealing with variable length input with 1dConv & RNN's\n",
    "\n",
    "Let's create two dummy series of two different length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T20:27:55.785628Z",
     "start_time": "2019-12-13T20:27:55.773704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7308, 0.6269, 0.5641, 0.7908, 0.4936, 0.2229, 0.8124, 0.2558,\n",
      "          0.0164, 0.8950, 0.6964, 0.9653, 0.6138, 0.1344, 0.1115, 0.3200,\n",
      "          0.9870, 0.8439, 0.0221, 0.1231, 0.1145, 0.7269, 0.1690, 0.8651,\n",
      "          0.2605, 0.2265, 0.6158, 0.3138, 0.0770, 0.6195, 0.2855, 0.6974,\n",
      "          0.6119]]])\n",
      "tensor([[[0.4041, 0.2329, 0.6244, 0.5621, 0.3285, 0.3897, 0.7083, 0.6154,\n",
      "          0.1115, 0.8091]]])\n"
     ]
    }
   ],
   "source": [
    "x_long = torch.rand(1,1,33)  ## Data needs to be 3d for 1d convolutions ! (batch,serie_size,seq)\n",
    "x_small = torch.rand(1,1,10)\n",
    "\n",
    "print(x_long)\n",
    "print(x_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## 1-Dimensional Convolutions:\n",
    "\n",
    "1D Convolutions are like a sliding window over the serie:\n",
    "\n",
    "`channel` is the number observations that belongs together, multivariable series have multiple channels (for example, RGB images have 3 channels)\n",
    "\n",
    "Convolutions have multiple parameters:\n",
    "\n",
    "[`torch.nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_modea='zeros')`](https://pytorch.org/docs/stable/nn.html#conv1d)\n",
    "\n",
    "\n",
    "- `stride` controls the stride for the cross-correlation, a single number or a one-element tuple.\n",
    "\n",
    "- `padding` controls the amount of implicit zero-paddings on both sides for padding number of points.\n",
    "\n",
    "- `dilation` controls the spacing between the kernel points; also known as the à trous algorithm. It is harder to describe, but this link has a nice visualization of what dilation does.\n",
    "\n",
    "- `groups` controls the connections between inputs and outputs. in_channels and out_channels must both be divisible by groups\n",
    "\n",
    "\n",
    "## [>> Have a look at this visualization to understand how they behave ! <<](https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Knowing the output size:\n",
    "\n",
    "This formula should give you the output size per channel\n",
    "\n",
    "$$ \\frac{(W−K+2P)}{S}+1$$\n",
    "\n",
    "- W is the input volume\n",
    "- K is the Kernel size\n",
    "- P is the padding\n",
    "- S is the stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic 1-d => one sliding window\n",
    "\n",
    "With one input channel and one output channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T20:34:43.353505Z",
     "start_time": "2019-12-13T20:34:43.342508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 30])\n",
      "tensor([[[ 0.1135, -0.0249,  0.1645,  0.2494, -0.1541,  0.1939,  0.2831,\n",
      "          -0.3274, -0.0752, -0.0008,  0.1953,  0.3943,  0.1733, -0.0819,\n",
      "          -0.3324, -0.0024,  0.5129,  0.2076, -0.0059, -0.2416,  0.1514,\n",
      "          -0.1296,  0.1839,  0.2123, -0.1285,  0.1134,  0.2273, -0.1548,\n",
      "           0.0649, -0.0631]]], grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([1, 1, 7])\n",
      "tensor([[[-0.1005, -0.0051,  0.1892,  0.0704, -0.1192,  0.0432,  0.3109]]],\n",
      "       grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "conv_module1 = torch.nn.Conv1d(1,1,4,stride=1)\n",
    "output_long = conv_module1(x_long)\n",
    "output_small = conv_module1(x_small)\n",
    "\n",
    "print(output_long.size()) #24-4+1 (we roll with 4-sized windows and calculate a filter) => 21 values\n",
    "print(output_long)\n",
    "\n",
    "\n",
    "print(output_small.size()) #24-4+1 (we roll with 4-sized windows and calculate a filter) => 21 values\n",
    "print(output_small)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### => The sizes are not the same :(\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic 1-d => multiple sliding windows + max-pooling along channels\n",
    "\n",
    "With one input channel and MORE output channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T20:38:50.734087Z",
     "start_time": "2019-12-13T20:38:50.723121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4])\n",
      "tensor([[0.0736, 0.0080, 0.6271, 0.4685]], grad_fn=<MaxBackward0>)\n",
      "\n",
      "torch.Size([1, 4])\n",
      "tensor([[-0.2602, -0.1710,  0.5110,  0.3589]], grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "conv_module1 = torch.nn.Conv1d(1,4,4)\n",
    "\n",
    "output_long,_ =  torch.max(conv_module1(x_long), dim=-1)\n",
    "output_small,_ = torch.max(conv_module1(x_small), dim=-1)\n",
    "\n",
    "\n",
    "\n",
    "print(output_long.size()) \n",
    "print(output_long)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(output_small.size()) \n",
    "print(output_small)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### => Now, they have the same size ! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN's are neural networks cells that processes the time serie sequentially (time-step after time-step) instead of in parallel like CNN's. This is because each output at time $t$ is conditioned on $t-1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T20:39:04.074905Z",
     "start_time": "2019-12-13T20:39:04.069936Z"
    }
   },
   "outputs": [],
   "source": [
    "x_long_rnn = torch.rand(1,33,6)  ## Data needs to be 3d for RNN ! (batch,seq,serie_size)\n",
    "x_small_rnn = torch.rand(1,12,6) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [`torch.nn` rnn'](https://pytorch.org/docs/stable/nn.html#recurrent-layers)\n",
    "\n",
    "\n",
    "You have two kinds:\n",
    "    - (RNN/GRU/LSTM) => These cells processes the whole sequence in one operation X(SEQ) => OUT \n",
    "    - (RNN/GRU/LSTM)Cell => These cells require a for loop to process a whole sequence X(s)=>X(e)=>X(q) => OUT\n",
    "    \n",
    " Both can take variable length inputs. For the former you'll have to pad with 0's so each sequences are of same length. The Latter (XCell) processes inputs via a `for` loop, so padding can be avoided.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T20:39:05.691388Z",
     "start_time": "2019-12-13T20:39:05.662858Z"
    }
   },
   "outputs": [],
   "source": [
    "small_rnn = nn.RNN(5,5)\n",
    "small_gru = nn.GRU(5,5)\n",
    "small_lstm = nn.LSTM(5,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch's RNN  all behave in the same way:\n",
    "\n",
    "### (TODO) => Try different the \"CELL\" variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T20:49:00.709408Z",
     "start_time": "2019-12-13T20:49:00.683811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:\n",
      "------\n",
      "tensor([[[ 0.1941,  0.1952, -0.1692,  0.0500,  0.0701],\n",
      "         [ 0.1619,  0.2273, -0.0063,  0.0054,  0.0337],\n",
      "         [ 0.1575,  0.1988, -0.0164,  0.0113,  0.1283],\n",
      "         [ 0.2124,  0.2129, -0.1088,  0.0130,  0.1008]]],\n",
      "       grad_fn=<StackBackward>)\n",
      "torch.Size([1, 4, 5])\n",
      "\n",
      "\n",
      "\n",
      "\"aggregation\"\n",
      "---\n",
      "tensor([[ 0.2124,  0.2129, -0.1088,  0.0130,  0.1008]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[ 0.2124,  0.2273, -0.0063,  0.0500,  0.1283]], grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "CELL = small_lstm#To complete #small_rnn # small_gru # small_lstm\n",
    "\n",
    "\n",
    "output,hidden = CELL(torch.rand(1,4,5)) # Processes a batch of 1 series of 4 timesteps of 5 values\n",
    "\n",
    "print(\"output:\")\n",
    "print(\"------\")\n",
    "print(output)\n",
    "print(output.size())\n",
    "\n",
    "\n",
    "full_seq_rnn = output[:,-1,:] # We select the output of the last timestep.\n",
    "full_seq_max,_ = torch.max(output,1) # we aggregate on the sequence dimension\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"\\\"aggregation\\\"\")\n",
    "print(\"---\")\n",
    "print(full_seq_rnn)\n",
    "print(full_seq_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output size has the same length at the sequence because there is one output per timestep (dimension #1);\n",
    "To have\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (TODO) process `x_long_rnn` and `x_small_rnn` with a `rnn_cell` so they have the same size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T20:56:54.553831Z",
     "start_time": "2019-12-13T20:56:54.545864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "Outputs are of equal sizes: True\n"
     ]
    }
   ],
   "source": [
    "rnn_cell = nn.RNN(6, 10)## To complete\n",
    "\n",
    "out_long,_ = rnn_cell(x_long_rnn)\n",
    "out_small,_ = rnn_cell(x_small_rnn)\n",
    "\n",
    "out_long = out_long[:,-1,:] # to complete\n",
    "out_small = out_small[:,-1,:] # to complete\n",
    "\n",
    "print(out_small.size())\n",
    "print(out_long.size())\n",
    "\n",
    "\n",
    "print(\"Outputs are of equal sizes:\", out_long.size() == out_small.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### => Take a moment to ponder on what output size is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch's Cells also all *nearly behave in the same way:\n",
    "\n",
    "*The LSTMCell output is a tuple of tensors instead of just one tensor (it returns cell state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T20:57:09.533913Z",
     "start_time": "2019-12-13T20:57:09.523913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0337, -0.3135,  0.3543, -0.1711,  0.4147]], grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_rnnC = nn.RNNCell(5,5)\n",
    "small_gruC = nn.GRUCell(5,5)\n",
    "small_lstmC = nn.LSTMCell(5,5)\n",
    "\n",
    "small_rnnC(torch.rand(1,5)) # Processes one example of size 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T20:59:40.450140Z",
     "start_time": "2019-12-13T20:59:40.429657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:\n",
      "------\n",
      "[tensor([[ 0.1333, -0.0484, -0.0762,  0.0455,  0.0462]], grad_fn=<MulBackward0>), tensor([[ 0.1210, -0.0565, -0.0264,  0.0368,  0.1060]], grad_fn=<MulBackward0>), tensor([[ 0.1542, -0.0217, -0.1352,  0.0074,  0.0390]], grad_fn=<MulBackward0>), tensor([[ 0.1939, -0.0454, -0.1444,  0.0185,  0.1155]], grad_fn=<MulBackward0>)]\n",
      "\n",
      "outputs.size()\n",
      "------\n",
      "[torch.Size([1, 5]), torch.Size([1, 5]), torch.Size([1, 5]), torch.Size([1, 5])]\n",
      "\n",
      "\n",
      "\n",
      "aggregation\n",
      "------\n",
      "tensor([[ 0.1939, -0.0454, -0.1444,  0.0185,  0.1155]], grad_fn=<MulBackward0>)\n",
      "tensor([ 0.1939, -0.0217, -0.0264,  0.0455,  0.1155], grad_fn=<MaxBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CELL = small_lstmC#To complete #small_rnnC # small_gruC # small_lstmC\n",
    "\n",
    "\n",
    "input_seq = torch.rand(1,4,5)\n",
    "\n",
    "outputs = []\n",
    "for i in range(input_seq.size(1)): #for every indices of the sequence\n",
    "    \n",
    "    input_vec = input_seq[:,i,:]     # we take the vector of one timestep\n",
    "    output = CELL(input_vec) # Processes a batch of 1 series of 4 timesteps of 5 values\n",
    "    \n",
    "    if type(output) is tuple: # if it's a lstm\n",
    "        output,_ = output\n",
    "        \n",
    "    outputs.append(output)\n",
    "        \n",
    "        \n",
    "print(\"outputs:\")\n",
    "print(\"------\")\n",
    "print(outputs)\n",
    "print(\"\")\n",
    "print(\"outputs.size()\")\n",
    "print(\"------\")\n",
    "print([x.size() for x in outputs])\n",
    "\n",
    "\n",
    "print(\"\\n\"*2)\n",
    "\n",
    "print(\"aggregation\")\n",
    "print(\"------\")\n",
    "\n",
    "concatenated = torch.cat(outputs,dim=0)\n",
    "maxed,_ = torch.max(concatenated,dim=0)\n",
    "\n",
    "\n",
    "print(outputs[-1])  #we can just select the last one\n",
    "print(maxed)\n",
    "print() #or do a max\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (TODO) process `x_long_rnn` and `x_small_rnn` with a `*(RNN)Cell` so they have the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T21:05:58.921817Z",
     "start_time": "2019-12-13T21:05:58.882081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "Outputs are of equal sizes: True\n"
     ]
    }
   ],
   "source": [
    "CELL_C = nn.RNNCell(6,10) ## To complete\n",
    "\n",
    "# To complete\n",
    "outputs = []\n",
    "for i in range(x_long_rnn.size(1)): #for every indices of the sequence\n",
    "    \n",
    "    input_vec = x_long_rnn[:,i,:]     # we take the vector of one timestep\n",
    "    output = CELL_C(input_vec) # Processes a batch of 1 series of 4 timesteps of 5 values\n",
    "    \n",
    "    if type(output) is tuple: # if it's a lstm\n",
    "        output,_ = output\n",
    "        \n",
    "    outputs.append(output)\n",
    "out_long = outputs[-1]\n",
    "    \n",
    "outputs = []\n",
    "for i in range(x_small_rnn.size(1)): #for every indices of the sequence\n",
    "    \n",
    "    input_vec = x_small_rnn[:,i,:]     # we take the vector of one timestep\n",
    "    output = CELL_C(input_vec) # Processes a batch of 1 series of 4 timesteps of 5 values\n",
    "    \n",
    "    if type(output) is tuple: # if it's a lstm\n",
    "        output,_ = output\n",
    "        \n",
    "    outputs.append(output)\n",
    "out_small = outputs[-1]\n",
    "\n",
    "print(out_small.size())\n",
    "print(out_long.size())\n",
    "\n",
    "\n",
    "print(\"Outputs are of equal sizes:\", out_long.size() == out_small.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (B) Using those parts for classification\n",
    "## Here, we are in the supervised learning framework: Signal classification\n",
    "\n",
    "###  We propose to reuse our simple timeseries classification task to tryout those convolutions/rnn's\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this dataset, we'll do the same task as before: prediction of the day of the week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Loading data/create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T22:56:42.978257Z",
     "start_time": "2019-12-13T22:56:41.074432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lets load the data and only consider the count as a serie.\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/cedias/csvdata/master/train.csv\",parse_dates=[\"datetime\"],usecols=['datetime','count'])\n",
    "df.head()\n",
    "\n",
    "df[\"y\"] = df.datetime.dt.weekday\n",
    "df[\"day\"] = df.datetime.dt.day\n",
    "df[\"hour\"] = df.datetime.dt.hour\n",
    "df[\"month\"] = df.datetime.dt.month\n",
    "df[\"time\"] = df.datetime.dt.time\n",
    "df[\"year\"] = df.datetime.dt.year\n",
    "\n",
    "hour_index = list(range(24))\n",
    "\n",
    "def paddedlist(df):\n",
    "    ndf = df.set_index(\"hour\")\n",
    "    \n",
    "    if len(df.index.values) < 24:\n",
    "        ndf = ndf.reindex(hour_index).fillna(0)\n",
    "     \n",
    "    # Here: I fill missing data with a 0, I could have used other strategies:\n",
    "    #pad / ffill: propagate last valid observation forward to next valid\n",
    "    #backfill / bfill: use next valid observation to fill gap\n",
    "    #nearest: use nearest valid observations to fill gap\n",
    "        \n",
    "    counts = ndf[\"count\"].tolist()\n",
    "    weekday = ndf.iloc[0][\"y\"]\n",
    "    \n",
    "    return  (counts,weekday)\n",
    "\n",
    "\n",
    "X,Y = zip(*(df.groupby([\"day\",\"month\",\"year\"])[\"hour\",\"count\",\"y\"]\n",
    "            .apply(paddedlist)\n",
    "            .reset_index(drop=True)\n",
    "            .sample(frac=1)\n",
    "            .tolist()\n",
    "           ))\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "\n",
    "for x,y in zip(X[:5],Y[:5]):\n",
    "    plt.plot(x,label=int(y))\n",
    "    plt.legend(title=\"signal class\")\n",
    "    \n",
    "X_train = X[:-42]\n",
    "Y_train = Y[:-42]\n",
    "\n",
    "X_test = X[-42:]\n",
    "Y_test = Y[-42:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First - two really simple convolutionnal Neural Nets:\n",
    "\n",
    "**Note**: We will build non-batched implementation for simplicity, but in practical you'll work with batches of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (TODO): Complete the following networks by calculating all the convolutions output size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T22:56:57.263120Z",
     "start_time": "2019-12-13T22:56:57.253116Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class EasyNet(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super(EasyNet, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(1,1,1) # => yields 24 values\n",
    "        self.conv2 = torch.nn.Conv1d(1,1,2) # => yields 23 values\n",
    "        self.conv4 = torch.nn.Conv1d(1,1,4) # => yields 21 values \n",
    "        self.conv8 = torch.nn.Conv1d(1,1,8) # => ...\n",
    "        self.conv12 = torch.nn.Conv1d(1,1,12)\n",
    "        self.conv24 = torch.nn.Conv1d(1,1,24)\n",
    "        \n",
    "        size_all_convs =  24+23+21+17+13+1# To complete\n",
    "        \n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        \n",
    "        print(size_all_convs//2)\n",
    "        \n",
    "        self.t1 = nn.Linear(size_all_convs, 24)\n",
    "        self.t2 = nn.Linear(24, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "        all_convs = torch.cat([self.conv1(x),self.conv2(x),self.conv4(x),self.conv8(x),self.conv12(x),self.conv24(x)],dim=-1)\n",
    "        first_transform = torch.tanh(self.t1(all_convs))\n",
    "        second_transform = self.t2(first_transform)\n",
    "        \n",
    "        output = second_transform \n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A small test case to test if the network works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T22:56:59.329698Z",
     "start_time": "2019-12-13T22:56:59.318703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "tensor([[[ 0.1972, -0.1225, -0.4855,  0.2735,  0.0479, -0.4777, -0.6402]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "net = EasyNet(7) # We do 7 way classification\n",
    "\n",
    "data_point = torch.Tensor(X[0]).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "print(net(data_point))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (TODO) Optimizing a model, quickly:\n",
    " => Complete this rather simple model optimization routine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T22:57:18.159580Z",
     "start_time": "2019-12-13T22:57:05.086490Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 0\n",
      "INFO:root:Iteration 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 1.9561487830779403\n",
      "Test accuracy :  23.809523809523807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 1.8281535460177252\n",
      "Test accuracy :  28.57142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 1.7618303632966563\n",
      "Test accuracy :  30.952380952380953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 1.7096119986640081\n",
      "Test accuracy :  30.952380952380953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 1.6457652464005106\n",
      "Test accuracy :  35.714285714285715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 1.5994003577796734\n",
      "Test accuracy :  35.714285714285715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 1.587937009219386\n",
      "Test accuracy :  28.57142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 1.609453706205755\n",
      "Test accuracy :  33.33333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 1.5571817898232003\n",
      "Test accuracy :  28.57142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 1.542158166423512\n",
      "Test accuracy :  26.190476190476193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 1.52712438662271\n",
      "Test accuracy :  35.714285714285715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 1.5095953496469967\n",
      "Test accuracy :  26.190476190476193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 1.5312262449575507\n",
      "Test accuracy :  38.095238095238095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 1.501361796533428\n",
      "Test accuracy :  26.190476190476193\n",
      "Train loss : 1.484779944886332\n",
      "Test accuracy :  30.952380952380953\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "model = net\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(15): # doing 15 epochs\n",
    "    logging.info(\"Iteration %d\", epoch)\n",
    "\n",
    "    sum_loss = 0\n",
    "    optim.zero_grad() # we reset gradients\n",
    "    for i,(x,y) in enumerate(zip(X_train,Y_train)): \n",
    "        \n",
    "        x = torch.Tensor(x).unsqueeze(0).unsqueeze(0)\n",
    "        y = torch.LongTensor([y])\n",
    "                \n",
    "        \n",
    "\n",
    "        yhat = model(x)## to complete\n",
    "        \n",
    "        yhat = yhat.squeeze(0)\n",
    "        \n",
    "        ex_loss = loss(yhat,y)## to complete\n",
    "        ex_loss.backward()\n",
    "\n",
    "\n",
    "        sum_loss += ex_loss.item()\n",
    "        \n",
    "        if i% BATCH_SIZE ==0:\n",
    "            optim.step()\n",
    "    \n",
    "    print(\"Train loss :\", sum_loss/len(X_train))\n",
    "    \n",
    "    sum_pred = 0\n",
    "    \n",
    "    for x,y in zip(X_test,Y_test): \n",
    "        \n",
    "        x = torch.Tensor(x).unsqueeze(0).unsqueeze(0)\n",
    "        y = torch.LongTensor([y])\n",
    "                \n",
    "        yhat = model(x)\n",
    "        \n",
    "        yhat = yhat.squeeze(0)\n",
    "        _,inds = torch.max(yhat,dim=-1)\n",
    "\n",
    "        if inds == y:\n",
    "            sum_pred +=1\n",
    "        \n",
    "    \n",
    "    print(\"Test accuracy : \",sum_pred/len(X_test) *100) \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (TODO) Now let's try max pooling on \"channels\"\n",
    "\n",
    "=> You have to do a `torch.max` on the channel dimensions so convolutions yields same size tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T23:00:57.453848Z",
     "start_time": "2019-12-13T23:00:57.444849Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class EasierNet(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super(EasierNet, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(1,128,8)\n",
    "    \n",
    "        self.t1 = nn.Linear(128, 64)\n",
    "        self.t2 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        all_convs,_ = torch.max(self.conv1(x),dim=-1)##to complete\n",
    "        first_transform = torch.dropout(torch.relu(self.t1(all_convs)),p=0.1,train=self.training)\n",
    "        second_transform = self.t2(first_transform)\n",
    "        \n",
    "        output = second_transform \n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T23:04:52.471543Z",
     "start_time": "2019-12-13T23:04:52.464569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -8.1670,   2.6025,  18.1948, -10.9893,  96.9194,  48.0193,  22.3850]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "net2 = EasierNet(7) # We do 7 way classificationa\n",
    "\n",
    "data_point = torch.Tensor(X[0]).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "print(net2(data_point))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Todo) Simple optimizing scheme : SGD\n",
    "\n",
    "### Complete the following cell. Also, the implementation here is not batched: try to add gradient batching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T23:05:03.153563Z",
     "start_time": "2019-12-13T23:04:53.132606Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 0\n",
      "INFO:root:Iteration 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 26.339937345296974\n",
      "Test Accuracy: 11.904761904761903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9589556153269783\n",
      "Test Accuracy: 11.904761904761903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.94823459064327\n",
      "Test Accuracy: 11.904761904761903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.947786227516506\n",
      "Test Accuracy: 11.904761904761903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9474758353210302\n",
      "Test Accuracy: 11.904761904761903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.947305016471568\n",
      "Test Accuracy: 16.666666666666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9472491807407803\n",
      "Test Accuracy: 16.666666666666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9472732561222021\n",
      "Test Accuracy: 16.666666666666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9473413131087298\n",
      "Test Accuracy: 16.666666666666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9474234002223914\n",
      "Test Accuracy: 14.285714285714285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9474996610540123\n",
      "Test Accuracy: 14.285714285714285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.947560805629417\n",
      "Test Accuracy: 14.285714285714285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9476054091960335\n",
      "Test Accuracy: 14.285714285714285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9476360050952377\n",
      "Test Accuracy: 14.285714285714285\n",
      "Training loss: 1.9476561629829776\n",
      "Test Accuracy: 14.285714285714285\n"
     ]
    }
   ],
   "source": [
    "import torch.optim\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "\n",
    "model = net2\n",
    "optim = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(15): # doing 15 epochs\n",
    "    logging.info(\"Iteration %d\", epoch)\n",
    "\n",
    "    sum_loss = 0\n",
    "    \n",
    "    optim.zero_grad() # we reset gradients\n",
    "    model.train() #we set model in train mode\n",
    "    for i,(x,y) in enumerate(zip(X_train,Y_train)): \n",
    "        \n",
    "        x = torch.Tensor(x).unsqueeze(0).unsqueeze(0)\n",
    "        y = torch.LongTensor([y])\n",
    "                \n",
    "\n",
    "        yhat = model(x)# To complete\n",
    "        yhat = yhat\n",
    "       \n",
    "        \n",
    "        l = loss(yhat,y)\n",
    "\n",
    "        sum_loss+=l.item()\n",
    "        l.backward()\n",
    "        \n",
    "        optim.step()\n",
    "    \n",
    "    \n",
    "    print(\"Training loss:\", sum_loss/len(X_train))\n",
    "    \n",
    "    sum_pred = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for x,y in zip(X_test,Y_test): \n",
    "        \n",
    "        x = torch.Tensor(x).unsqueeze(0).unsqueeze(0)\n",
    "        y = torch.LongTensor([y])\n",
    "                \n",
    "        yhat = model(x)\n",
    "        \n",
    "        yhat = yhat.squeeze(0)\n",
    "        _,inds = torch.max(yhat,dim=-1)\n",
    "\n",
    "        if inds == y:\n",
    "            sum_pred +=1\n",
    "        \n",
    "    \n",
    "    print(\"Test Accuracy:\", sum_pred/len(X_test) *100) \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second:  Two different RNN's : One with max pooling, one without"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (TODO) RNN: Max-pooling of all timestep\n",
    "\n",
    " => Here we want a model which does max pooling on all rnn's outputs to concatenate them in a single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T23:05:35.835431Z",
     "start_time": "2019-12-13T23:05:35.828430Z"
    }
   },
   "outputs": [],
   "source": [
    "class EasyRecNet(nn.Module):\n",
    "    def __init__(self,num_classes,rnn_cell=nn.RNN):\n",
    "        super(EasyRecNet, self).__init__()\n",
    "        \n",
    "        self.rnn = rnn_cell(1,num_classes*2)    \n",
    "        self.t1 = nn.Linear(num_classes*2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        seq,_ = self.rnn(x)\n",
    "        \n",
    "        pooled,_ = torch.max(seq,dim=1)## To complete\n",
    "        output = self.t1(pooled) \n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Test case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T23:05:39.057098Z",
     "start_time": "2019-12-13T23:05:39.049100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1113,  0.0042,  0.4445,  0.1260,  0.4665, -0.1730, -0.1361]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "net3 = EasyRecNet(7,nn.RNN) # We do 7 way classification with a classic RNN\n",
    "\n",
    "data_point = torch.Tensor(X[0]).unsqueeze(0).unsqueeze(-1)\n",
    "\n",
    "\n",
    "print(net3(data_point))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (TODO) Experiment with multiple rnn cells \n",
    "#### Optimizing again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T23:06:08.863428Z",
     "start_time": "2019-12-13T23:06:00.098523Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 0\n",
      "INFO:root:Iteration 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9713930850443633\n",
      "Test Accuracy: 14.285714285714285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9599222419918447\n",
      "Test Accuracy: 14.285714285714285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9511438274153188\n",
      "Test Accuracy: 14.285714285714285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9436890131609452\n",
      "Test Accuracy: 21.428571428571427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.938399334748586\n",
      "Test Accuracy: 23.809523809523807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9345851917773629\n",
      "Test Accuracy: 21.428571428571427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9279683727573083\n",
      "Test Accuracy: 19.047619047619047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.918659352449979\n",
      "Test Accuracy: 21.428571428571427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9097980756114648\n",
      "Test Accuracy: 21.428571428571427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9041906600989005\n",
      "Test Accuracy: 16.666666666666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.8981239239950687\n",
      "Test Accuracy: 16.666666666666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.891973924809608\n",
      "Test Accuracy: 16.666666666666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.8859126832750108\n",
      "Test Accuracy: 16.666666666666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.8794916634974272\n",
      "Test Accuracy: 16.666666666666664\n",
      "Training loss: 1.876926685013057\n",
      "Test Accuracy: 16.666666666666664\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "CELL_RNN = nn.LSTM#TO complete \n",
    "\n",
    "net3 = EasyRecNet(7,CELL_RNN) # We do 7 way classification with a classic RNN\n",
    "\n",
    "\n",
    "model = net3\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(15): # doing 15 epochs\n",
    "    logging.info(\"Iteration %d\", epoch)\n",
    "\n",
    "    sum_loss = 0\n",
    "    \n",
    "    optim.zero_grad() # we reset gradients\n",
    "    model.train() #we set model in train mode\n",
    "    for i,(x,y) in enumerate(zip(X_train,Y_train)): \n",
    "        \n",
    "        x = torch.Tensor(x).unsqueeze(0).unsqueeze(-1)\n",
    "        y = torch.LongTensor([y])\n",
    "                \n",
    "\n",
    "        yhat = model(x) \n",
    "        yhat = yhat\n",
    "       \n",
    "        l = loss(yhat,y)\n",
    "\n",
    "        sum_loss+=l.item()\n",
    "        l.backward()\n",
    "        \n",
    "        if i % BATCH_SIZE == 0: \n",
    "            optim.step()\n",
    "    \n",
    "    \n",
    "    print(\"Training loss:\", sum_loss/len(X_train))\n",
    "    \n",
    "    sum_pred = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for x,y in zip(X_test,Y_test): \n",
    "        \n",
    "        x = torch.Tensor(x).unsqueeze(0).unsqueeze(-1)\n",
    "        y = torch.LongTensor([y])\n",
    "                \n",
    "        yhat = model(x)\n",
    "        \n",
    "        yhat = yhat.squeeze(0)\n",
    "        _,inds = torch.max(yhat,dim=-1)\n",
    "\n",
    "        if inds == y:\n",
    "            sum_pred +=1\n",
    "        \n",
    "    \n",
    "    print(\"Test Accuracy:\", sum_pred/len(X_test) *100) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (TODO) : RNN: Taking the final output as a sequence aggregate\n",
    "\n",
    " => Try to Select the right output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T23:07:21.176159Z",
     "start_time": "2019-12-13T23:07:21.171157Z"
    }
   },
   "outputs": [],
   "source": [
    "class EasierRecNet(nn.Module):\n",
    "    def __init__(self,num_classes,rnn_cell=nn.RNN):\n",
    "        super(EasierRecNet, self).__init__()\n",
    "        \n",
    "        self.rnn = rnn_cell(1,num_classes*2)    \n",
    "        self.t1 = nn.Linear(num_classes*2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        seq,_ = self.rnn(x)\n",
    "        \n",
    "        final_rnn_output = seq[:,-1,:]# to complete\n",
    "        output = self.t1(final_rnn_output) \n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Test case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T23:07:25.620246Z",
     "start_time": "2019-12-13T23:07:25.612210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7651,  0.3419, -0.2081,  0.4012, -1.2053,  0.4203,  0.5294]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "net4 = EasierRecNet(7,nn.RNN) # We do 7 way classification with a classic RNN\n",
    "\n",
    "data_point = torch.Tensor(X[0]).unsqueeze(0).unsqueeze(-1)\n",
    "\n",
    "\n",
    "print(net4(data_point))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (TODO) The optimization routine\n",
    "\n",
    "=> once again choose whatever rnn you'd like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T23:07:50.385421Z",
     "start_time": "2019-12-13T23:07:42.695116Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 0\n",
      "INFO:root:Iteration 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9690612508478949\n",
      "Test Accuracy: 21.428571428571427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9573452864292162\n",
      "Test Accuracy: 21.428571428571427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9510541834693025\n",
      "Test Accuracy: 21.428571428571427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9463157650929142\n",
      "Test Accuracy: 21.428571428571427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9394943144010461\n",
      "Test Accuracy: 19.047619047619047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.932447450172498\n",
      "Test Accuracy: 19.047619047619047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9261521023252737\n",
      "Test Accuracy: 19.047619047619047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9186058721104682\n",
      "Test Accuracy: 19.047619047619047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.909522465461694\n",
      "Test Accuracy: 21.428571428571427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9017430379770803\n",
      "Test Accuracy: 21.428571428571427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.8990088119598978\n",
      "Test Accuracy: 19.047619047619047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.8931471783181895\n",
      "Test Accuracy: 11.904761904761903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.894536482827099\n",
      "Test Accuracy: 16.666666666666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.8881498860276265\n",
      "Test Accuracy: 26.190476190476193\n",
      "Training loss: 1.8949098264537572\n",
      "Test Accuracy: 21.428571428571427\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "CELL_RNN =  nn.LSTM#TO complete\n",
    "\n",
    "net4 = EasierRecNet(7,CELL_RNN) # We do 7 way classification with a classic RNN\n",
    "\n",
    "\n",
    "model = net4\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(15): # doing 15 epochs\n",
    "    logging.info(\"Iteration %d\", epoch)\n",
    "\n",
    "    sum_loss = 0\n",
    "    \n",
    "    optim.zero_grad() # we reset gradients\n",
    "    model.train() #we set model in train mode\n",
    "    for i,(x,y) in enumerate(zip(X_train,Y_train)): \n",
    "        \n",
    "        x = torch.Tensor(x).unsqueeze(0).unsqueeze(-1)\n",
    "        y = torch.LongTensor([y])\n",
    "                \n",
    "\n",
    "        yhat = model(x)\n",
    "        yhat = yhat\n",
    "       \n",
    "        l = loss(yhat,y)\n",
    "\n",
    "        sum_loss+=l.item()\n",
    "        l.backward()\n",
    "        \n",
    "        if i % BATCH_SIZE == 0: \n",
    "            optim.step()\n",
    "    \n",
    "    \n",
    "    print(\"Training loss:\", sum_loss/len(X_train))\n",
    "    \n",
    "    sum_pred = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for x,y in zip(X_test,Y_test): \n",
    "        \n",
    "        x = torch.Tensor(x).unsqueeze(0).unsqueeze(-1)\n",
    "        y = torch.LongTensor([y])\n",
    "                \n",
    "        yhat = model(x)\n",
    "        \n",
    "        yhat = yhat.squeeze(0)\n",
    "        _,inds = torch.max(yhat,dim=-1)\n",
    "\n",
    "        if inds == y:\n",
    "            sum_pred +=1\n",
    "        \n",
    "    \n",
    "    print(\"Test Accuracy:\", sum_pred/len(X_test) *100) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## => Take some time to ponder on how dimensions interacts and how different RNNs work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (C) RNNs forecasting : temperature prediciton\n",
    "\n",
    "### Now, we propose to do a little temperature forecast exercise, using rnn's.\n",
    "\n",
    "### Our task is the following: given a series of $t$ temperatures, the goal is to predict the next temperatures $t+1, t+2, t+...$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T23:07:59.546195Z",
     "start_time": "2019-12-13T23:07:59.541195Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import unicodedata\n",
    "import string\n",
    "from itertools import chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A quick glance at the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T23:08:02.217882Z",
     "start_time": "2019-12-13T23:08:00.406016Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Vancouver</th>\n",
       "      <th>Portland</th>\n",
       "      <th>San Francisco</th>\n",
       "      <th>Seattle</th>\n",
       "      <th>Los Angeles</th>\n",
       "      <th>San Diego</th>\n",
       "      <th>Las Vegas</th>\n",
       "      <th>Phoenix</th>\n",
       "      <th>Albuquerque</th>\n",
       "      <th>...</th>\n",
       "      <th>Detroit</th>\n",
       "      <th>Jacksonville</th>\n",
       "      <th>Charlotte</th>\n",
       "      <th>Miami</th>\n",
       "      <th>Pittsburgh</th>\n",
       "      <th>Toronto</th>\n",
       "      <th>Philadelphia</th>\n",
       "      <th>New York</th>\n",
       "      <th>Montreal</th>\n",
       "      <th>Boston</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-01 13:00:00</td>\n",
       "      <td>284.630000</td>\n",
       "      <td>282.080000</td>\n",
       "      <td>289.480000</td>\n",
       "      <td>281.800000</td>\n",
       "      <td>291.870000</td>\n",
       "      <td>291.530000</td>\n",
       "      <td>293.410000</td>\n",
       "      <td>296.600000</td>\n",
       "      <td>285.120000</td>\n",
       "      <td>...</td>\n",
       "      <td>284.030000</td>\n",
       "      <td>298.170000</td>\n",
       "      <td>288.650000</td>\n",
       "      <td>299.720000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>286.260000</td>\n",
       "      <td>285.630000</td>\n",
       "      <td>288.220000</td>\n",
       "      <td>285.830000</td>\n",
       "      <td>287.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-01 14:00:00</td>\n",
       "      <td>284.629041</td>\n",
       "      <td>282.083252</td>\n",
       "      <td>289.474993</td>\n",
       "      <td>281.797217</td>\n",
       "      <td>291.868186</td>\n",
       "      <td>291.533501</td>\n",
       "      <td>293.403141</td>\n",
       "      <td>296.608509</td>\n",
       "      <td>285.154558</td>\n",
       "      <td>...</td>\n",
       "      <td>284.069789</td>\n",
       "      <td>298.205230</td>\n",
       "      <td>288.650172</td>\n",
       "      <td>299.732518</td>\n",
       "      <td>281.024767</td>\n",
       "      <td>286.262541</td>\n",
       "      <td>285.663208</td>\n",
       "      <td>288.247676</td>\n",
       "      <td>285.834650</td>\n",
       "      <td>287.186092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-01 15:00:00</td>\n",
       "      <td>284.626998</td>\n",
       "      <td>282.091866</td>\n",
       "      <td>289.460618</td>\n",
       "      <td>281.789833</td>\n",
       "      <td>291.862844</td>\n",
       "      <td>291.543355</td>\n",
       "      <td>293.392177</td>\n",
       "      <td>296.631487</td>\n",
       "      <td>285.233952</td>\n",
       "      <td>...</td>\n",
       "      <td>284.173965</td>\n",
       "      <td>298.299595</td>\n",
       "      <td>288.650582</td>\n",
       "      <td>299.766579</td>\n",
       "      <td>281.088319</td>\n",
       "      <td>286.269518</td>\n",
       "      <td>285.756824</td>\n",
       "      <td>288.326940</td>\n",
       "      <td>285.847790</td>\n",
       "      <td>287.231672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-01 16:00:00</td>\n",
       "      <td>284.624955</td>\n",
       "      <td>282.100481</td>\n",
       "      <td>289.446243</td>\n",
       "      <td>281.782449</td>\n",
       "      <td>291.857503</td>\n",
       "      <td>291.553209</td>\n",
       "      <td>293.381213</td>\n",
       "      <td>296.654466</td>\n",
       "      <td>285.313345</td>\n",
       "      <td>...</td>\n",
       "      <td>284.278140</td>\n",
       "      <td>298.393961</td>\n",
       "      <td>288.650991</td>\n",
       "      <td>299.800641</td>\n",
       "      <td>281.151870</td>\n",
       "      <td>286.276496</td>\n",
       "      <td>285.850440</td>\n",
       "      <td>288.406203</td>\n",
       "      <td>285.860929</td>\n",
       "      <td>287.277251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-01 17:00:00</td>\n",
       "      <td>284.622911</td>\n",
       "      <td>282.109095</td>\n",
       "      <td>289.431869</td>\n",
       "      <td>281.775065</td>\n",
       "      <td>291.852162</td>\n",
       "      <td>291.563063</td>\n",
       "      <td>293.370249</td>\n",
       "      <td>296.677445</td>\n",
       "      <td>285.392738</td>\n",
       "      <td>...</td>\n",
       "      <td>284.382316</td>\n",
       "      <td>298.488326</td>\n",
       "      <td>288.651401</td>\n",
       "      <td>299.834703</td>\n",
       "      <td>281.215421</td>\n",
       "      <td>286.283473</td>\n",
       "      <td>285.944057</td>\n",
       "      <td>288.485467</td>\n",
       "      <td>285.874069</td>\n",
       "      <td>287.322831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime   Vancouver    Portland  San Francisco     Seattle  \\\n",
       "0  2012-10-01 13:00:00  284.630000  282.080000     289.480000  281.800000   \n",
       "1  2012-10-01 14:00:00  284.629041  282.083252     289.474993  281.797217   \n",
       "2  2012-10-01 15:00:00  284.626998  282.091866     289.460618  281.789833   \n",
       "3  2012-10-01 16:00:00  284.624955  282.100481     289.446243  281.782449   \n",
       "4  2012-10-01 17:00:00  284.622911  282.109095     289.431869  281.775065   \n",
       "\n",
       "   Los Angeles   San Diego   Las Vegas     Phoenix  Albuquerque  ...  \\\n",
       "0   291.870000  291.530000  293.410000  296.600000   285.120000  ...   \n",
       "1   291.868186  291.533501  293.403141  296.608509   285.154558  ...   \n",
       "2   291.862844  291.543355  293.392177  296.631487   285.233952  ...   \n",
       "3   291.857503  291.553209  293.381213  296.654466   285.313345  ...   \n",
       "4   291.852162  291.563063  293.370249  296.677445   285.392738  ...   \n",
       "\n",
       "      Detroit  Jacksonville   Charlotte       Miami  Pittsburgh     Toronto  \\\n",
       "0  284.030000    298.170000  288.650000  299.720000  281.000000  286.260000   \n",
       "1  284.069789    298.205230  288.650172  299.732518  281.024767  286.262541   \n",
       "2  284.173965    298.299595  288.650582  299.766579  281.088319  286.269518   \n",
       "3  284.278140    298.393961  288.650991  299.800641  281.151870  286.276496   \n",
       "4  284.382316    298.488326  288.651401  299.834703  281.215421  286.283473   \n",
       "\n",
       "   Philadelphia    New York    Montreal      Boston  \n",
       "0    285.630000  288.220000  285.830000  287.170000  \n",
       "1    285.663208  288.247676  285.834650  287.186092  \n",
       "2    285.756824  288.326940  285.847790  287.231672  \n",
       "3    285.850440  288.406203  285.860929  287.277251  \n",
       "4    285.944057  288.485467  285.874069  287.322831  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEMP_DATA = pd.read_csv(\"https://raw.githubusercontent.com/cedias/csvdata/master/tempAMAL_train.csv\")\n",
    "TEMP_DATA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T23:08:03.841092Z",
     "start_time": "2019-12-13T23:08:03.834065Z"
    }
   },
   "outputs": [],
   "source": [
    "def fill_na(mat):\n",
    "    ix,iy = np.where(np.isnan(mat))\n",
    "    for i,j in zip(ix,iy):\n",
    "        if np.isnan(mat[i+1,j]):\n",
    "            mat[i,j]=mat[i-1,j]\n",
    "        else:\n",
    "            mat[i,j]=(mat[i-1,j]+mat[i+1,j])/2.\n",
    "    return mat\n",
    "\n",
    "\n",
    "def read_temps():\n",
    "    \"\"\"\n",
    "    returns a tensor of temperature with mean interpolation for missing data\n",
    "    \"\"\"\n",
    "    return torch.tensor(fill_na(np.array(TEMP_DATA.iloc[:,1:])),dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T23:08:04.810176Z",
     "start_time": "2019-12-13T23:08:04.430091Z"
    }
   },
   "outputs": [],
   "source": [
    "#Checking if you have cuda enabled\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Forecast Dataset\n",
    "\n",
    "We create a dataset class to iterate on temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T23:08:08.049180Z",
     "start_time": "2019-12-13T23:08:08.040212Z"
    }
   },
   "outputs": [],
   "source": [
    "class ForecastTempDataset(Dataset):\n",
    "    \n",
    "    MAX,MIN = 330.,230.\n",
    "    \n",
    "    def __init__(self, x,length=20,nb=10000,test=False):\n",
    "        self.data,self.length,self.nb = (x-self.MIN)/(self.MAX-self.MIN) ,length,nb\n",
    "        self.size, self.classes = x.shape\n",
    "        self.indexes = [0]\n",
    "        self.nb_samples = 0\n",
    "        if (test):\n",
    "            self.indexes = np.arange(0,self.size,self.length)\n",
    "            self.nb_samples = len(self.indexes)-1\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.nb_samples:\n",
    "            return self.nb_samples\n",
    "        return self.nb\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        \"\"\" length X dim \"\"\"\n",
    "        if self.nb_samples:\n",
    "            return self.data[self.indexes[i]:self.indexes[i+1]-1,:],self.data[self.indexes[i]+1:self.indexes[i+1]]\n",
    "        \n",
    "        id = np.random.randint(self.size-self.length)\n",
    "        \n",
    "        return self.data[id:(id+self.length-1),:],self.data[id+1:(id+self.length)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The actual recurrent model (Vanilla version of a `nn.RNNCell`)\n",
    "\n",
    "Recall that Recurrent neural networks (RNNs) are neural nets that can deal with sequences of variable length (unlike feedforward nets). They are able to this by defining a recurrence relation over timesteps which is typically the following formula: \n",
    "\n",
    "### $$ S_{k} = f(S_{k-1} \\cdot W_{rec} + X_k \\cdot W_x) $$\n",
    "\n",
    "Where $S_k$ is the state at time k, $X_k$ an exogenous input at time k, $W_rec$ and $W_x$ are parameters like the weights parameters in feedforward nets. Note that the RNN can be viewed as a state model with a feedback loop . The state evolves over time due to the recurrence relation, and the feedback is fed back into the state with a delay of one timestep. This delayed feedback loop gives the model memory because it can remember information between timesteps in the states.\n",
    "The final output of the network $Y_k$ at a certain timestep k is typically computed from one or more states $S_{k−i}...S_{k+j}$.\n",
    "\n",
    "**Note that we can either compute the current state $S_k$ from the current input $X_k$ and previous state $S_{k−1}$, or predict the next state from $S_{k+1}$ from the current state $S_k$ and current input $X_k$. The difference of notation has not much effect on our model and depends on the task at hand. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T23:08:16.914536Z",
     "start_time": "2019-12-13T23:08:16.904488Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, inputdim,latentdim):\n",
    "        super(RNN,self).__init__()\n",
    "        \n",
    "        self.inputdim , self.latentdim = inputdim,latentdim\n",
    "        self.encoder = nn.Linear(inputdim,latentdim)\n",
    "        self.latent = nn.Linear(latentdim,latentdim)\n",
    "        \n",
    "    def forward(self,x,h=None):\n",
    "        \"\"\" x: length x batch x dim \"\"\"\n",
    "        hseq = []\n",
    "        \n",
    "        if h is None:\n",
    "            h = self.hzero(x.shape[1]).to(x.device)\n",
    "            \n",
    "        for i in range(x.shape[0]):\n",
    "            h = self.one_step(x[i],h)\n",
    "            hseq.append(h)\n",
    "            \n",
    "        return torch.stack(hseq)\n",
    "    \n",
    "    def one_step(self,x,h):\n",
    "        return  torch.tanh(self.encode(x)+self.latent(h))\n",
    "    \n",
    "    def encode(self,x):\n",
    "        return self.encoder(x.view(-1,self.inputdim))\n",
    "    \n",
    "    def hzero(self,batch_size):\n",
    "        return torch.zeros(batch_size,self.latentdim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The forecasting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T23:08:17.712182Z",
     "start_time": "2019-12-13T23:08:17.705187Z"
    }
   },
   "outputs": [],
   "source": [
    "def forecast(rnn,decoder,x,h=None,length=10):\n",
    "    \n",
    "    with torch.no_grad():    \n",
    "        if h is None:\n",
    "            h = rnn.hzero(x.shape[1]).to(x.device)\n",
    "            \n",
    "        h = rnn.forward(x,h)[-1]\n",
    "        x = decoder.forward(h)\n",
    "        yhat = [x]\n",
    "        \n",
    "        for i in range(length-1):\n",
    "            x = decoder.forward(rnn.one_step(x,h))\n",
    "            yhat.append(x)\n",
    "            \n",
    "    return torch.stack(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Here we wrap the optimization function so you can experiment with parameters\n",
    "\n",
    "- EPOCHS : Number of epochs\n",
    "- BATCH_SIZE : Batch size \n",
    "- LATENT : Size of the latent space learnt by the RNN\n",
    "- LENGTH : Size of the forecasting set while training\n",
    "- LENGTH_FC : Size of the test forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T23:28:29.790092Z",
     "start_time": "2019-12-13T23:28:29.704100Z"
    }
   },
   "outputs": [],
   "source": [
    "def training(EPOCHS = 100, BATCH_SIZE = 32,LATENT = 10,LENGTH= 100,LENGTH_FC = 30):\n",
    "    \n",
    "    data_temp = read_temps()\n",
    "    \n",
    "    id_split = int(data_temp.shape[0]*0.8)\n",
    "    \n",
    "    data_train = DataLoader(ForecastTempDataset(data_temp[:id_split,:],length=LENGTH),batch_size=BATCH_SIZE,shuffle=True)\n",
    "    data_test = DataLoader(ForecastTempDataset(data_temp[id_split:,:],test=True,length=LENGTH),batch_size=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "    rnn = RNN(data_temp.shape[1],LATENT)\n",
    "    \n",
    "    decoder = nn.Linear(LATENT,data_temp.shape[1])\n",
    "    \n",
    "    loss = torch.nn.MSELoss()\n",
    "    \n",
    "    optim = torch.optim.Adam(chain(rnn.parameters(),decoder.parameters()),lr=0.0001)\n",
    "\n",
    "    rnn = rnn.to(device)\n",
    "    decoder = decoder.to(device)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        logging.info(\"Iteration %d\", epoch)\n",
    "        suml = 0\n",
    "        err = 0\n",
    "        \n",
    "        for x,y in data_train: \n",
    "            l=0\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            h = rnn.forward(x.transpose(0,1))\n",
    "            yhat = decoder.forward(h.view(-1,LATENT)).view(x.size(1),x.size(0),data_temp.size(1))\n",
    "\n",
    "            l += loss(yhat,y.transpose(0,1))\n",
    "            \n",
    "            suml += l/len(data_train)\n",
    "            l.backward()\n",
    "            optim.step()\n",
    "            \n",
    "        logging.info(\"loss train : %f\",suml)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            l = 0\n",
    "            lf = 0\n",
    "            \n",
    "            for x,y in data_test:\n",
    "                x = x.to(device)\n",
    "                h = rnn.forward(x.transpose(0,1))\n",
    "                y = y.to(device)\n",
    "                yhat = decoder.forward(h.view(-1,LATENT)).view(x.size(1),x.size(0),data_temp.size(1))\n",
    "                l += loss(yhat,y.transpose(0,1))/len(data_test)\n",
    "                \n",
    "                ## ALL THE FORECAST happens here\n",
    "                yhat = forecast(rnn,decoder,x.transpose(0,1)[:-LENGTH_FC],length=LENGTH_FC)\n",
    "                \n",
    "                lf += loss(yhat,y.transpose(0,1)[-LENGTH_FC:])/len(data_test)\n",
    "                \n",
    "            logging.info(\"loss test : %f\",l)\n",
    "            logging.info(\"loss test forecast : %f\",lf)\n",
    "\n",
    "    return rnn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (TODO) experiment with different variables\n",
    "\n",
    "- What happens when you learn with less then what you predict\n",
    "- On the contrary, what happens if you learn with more\n",
    "- Does the Latent size really makes the performances better ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T23:41:11.013695Z",
     "start_time": "2019-12-13T23:35:10.919393Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 0\n",
      "INFO:root:loss train : 0.235312\n",
      "INFO:root:loss test : 0.109656\n",
      "INFO:root:loss test forecast : 0.161202\n",
      "INFO:root:Iteration 1\n",
      "INFO:root:loss train : 0.084452\n",
      "INFO:root:loss test : 0.036228\n",
      "INFO:root:loss test forecast : 0.040207\n",
      "INFO:root:Iteration 2\n",
      "INFO:root:loss train : 0.028341\n",
      "INFO:root:loss test : 0.013475\n",
      "INFO:root:loss test forecast : 0.014859\n",
      "INFO:root:Iteration 3\n",
      "INFO:root:loss train : 0.010558\n",
      "INFO:root:loss test : 0.007121\n",
      "INFO:root:loss test forecast : 0.009638\n",
      "INFO:root:Iteration 4\n",
      "INFO:root:loss train : 0.005992\n",
      "INFO:root:loss test : 0.006049\n",
      "INFO:root:loss test forecast : 0.009210\n",
      "INFO:root:Iteration 5\n",
      "INFO:root:loss train : 0.005027\n",
      "INFO:root:loss test : 0.005834\n",
      "INFO:root:loss test forecast : 0.009496\n",
      "INFO:root:Iteration 6\n",
      "INFO:root:loss train : 0.004609\n",
      "INFO:root:loss test : 0.005316\n",
      "INFO:root:loss test forecast : 0.008968\n",
      "INFO:root:Iteration 7\n",
      "INFO:root:loss train : 0.004232\n",
      "INFO:root:loss test : 0.005162\n",
      "INFO:root:loss test forecast : 0.008926\n",
      "INFO:root:Iteration 8\n",
      "INFO:root:loss train : 0.003888\n",
      "INFO:root:loss test : 0.004979\n",
      "INFO:root:loss test forecast : 0.008985\n",
      "INFO:root:Iteration 9\n",
      "INFO:root:loss train : 0.003630\n",
      "INFO:root:loss test : 0.004650\n",
      "INFO:root:loss test forecast : 0.008160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (encoder): Linear(in_features=30, out_features=10, bias=True)\n",
       "  (latent): Linear(in_features=10, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training(EPOCHS = 10, BATCH_SIZE = 32,LATENT = 10,LENGTH= 100,LENGTH_FC = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
